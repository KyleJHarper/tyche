1. ACCRS
     a) Create a reader/writer preference feature.  Stopping all readers for 1 writer seems unfair; maybe use
        pending writer count as part of a coin-toss to determine if a new reader will actually wait or grab a new
        pin anyway.  Statistically this will balance out and should help performance as reading/writing will be more
        fairly balanced (i.e.: more threads can keep working).
     b) Add options to emulate favoritism: what % is frequently used and how often are they reused vs others?
     c) A thread needs to manage the ACCRS logic for each manager.
     d) Research options to accommodate aging and if it's even necessary (newer buffers == more likely to reuse?)
        Perhaps buffer__initialize should set popularity to 1 or 3 so bits are 100 or 010 instead of 001.
        Results in triple or double protection.
     e) Research scan protection vs. protecting newer buffers.
     f) Create a way to determine how effective sweeping is and adjust it up/down... ?  Boundaries?
     g) Use comp_time and io_time to determine if giving more space to raw/comp is better.
        How to ensure this doesn't fly to 99% (boundaries?).
        Should buffers even track their individual times?  Doing so is going to result in us scanning the whole set of
          buffers in a list and that is going to be expensive.  Maybe the list should keep an array of aggregates and
          iterate through them to determine how to tune the ratios and call list__balance.
          (Note:  This would save 10 bytes per buffer, which is great.)
2. FAQ
     a) Why no size_t?  (Because I want to ensure minium sizes in almost all cases)
     b) Why so much uint/uintX_t?  Because I usually need to accommodate the given size and negative numbers don't exist.
     c) Why no <bla> optimization?  Probably because I'm new to C and didn't know about it.
     e) Why C?  To *hopefully* avoid bias in higher level langages; though they might have optimizations.
     f) Why lz4?  Partly it's compression speed+efficiency, but mostly it's decompression speed.
     g) Your page replacement is sub-optimal compared to <some_other_strategy>!
        Might be.  But it's fast enough to not be a bottleneck and prove the point I'm trying to make with compression.
3. Niceness & Bug Fixes
     a) Update ALLLLLL the documentation in the source files.
     b) When there isn't enough space in comp max_size for a single sweep, it hangs (100% cpu, not deadlock).
     c) Very first sweep of a run can deadlock... why?
     d) Debug logging is probably a good idea for Managers and Workers.
4. Single list.
     a) Get rid of the raw/comp list concept.
     b) Allow list__search to continue working while list__add() is working.
     c) Consider using __sync_fetch_and_add in place of mutex locks:
          1. list__add() for the count and size.
          2. list__sweep() for the sweeps++ and sweep_cost increments.
          3. list__search() restoration when a compressed buffer warrants it.
     d) When fixed ratio is low (-f 1) the sweep logic goes into a deadlock somehow.
     e) Pushing items off the compressed list still fails.  Need to debug (I think I'm checking raw).
